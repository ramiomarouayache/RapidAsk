---
slug: /tutorials/visual-characters
title: ðŸ¤– Visual characters
sidebar_position: 7
---

# Visual Characters

We use **Lottie animation** characters to mimic AI voice replies. These animations are lightweight and offer great performance on both web and mobile apps. You will get access to 5 unique, high-quality speaking characters with transparent backgrounds for various use cases.

![ai_characters](/img/characterss.webp)

### Build Your Own:

You can create your own speaking character using an image or a video (video is recommended). There are free tools available online to help you with this, and you'll find a variety of ready-made avatars to choose from, ranging from realistic to cartoon styles.

#### 1. **Using an Image**:
   - Ensure your image is a high-quality, front-facing portrait of a character (with eyes visible).
   - Once your image is ready, you can use AI platforms like **Heygen** to animate it and bring your character to life. 
   - Sign up at [Heygen](https://heygen.com/?sid=rewardful&via=rami-omar), then navigate to **Dashboard > Avatars > Create Video Avatars** and upload your image.
   - After a few minutes, your animated video avatar will be ready to go.
   - **Important**: Be sure to review Heygen's policies regarding commercial use to ensure compliance with their terms.

#### 2. **Using a Video**:
   - Once your video is ready, the next step is to convert it into a transparent Lottie animation file. Lottie animations are perfect for use in apps and websites due to their small file size and high resolution.

   ![ai_head_examples](/img/talking-head.webp)

---

...Once you get access, you will get more details on how to convert your characterâ€™s video into a transparent Lottie animation file. This ensures the highest resolution with the smallest file size, making it perfect for different use cases...

---

<details>
<summary>Sync character's mouth movements</summary>
1. Generate Speech Audio: Use OpenAI's TTS to convert text into speech mp3 audio.

2. Phoneme Timing: OpenAI TTS doesnâ€™t directly provide phoneme timings, so you may need to analyze the audio using external libraries or phonetic analysis to extract this data.

3. Create Lottie Animations with Visemes: Create a Lottie animation with frames corresponding to different mouth shapes (visemes) for each phoneme (e.g., "AH", "EE", "M"). This requires either generating or obtaining animations for each phoneme or a representative subset.

4. Synchronize Audio and Animation: Match the extracted phoneme timing with the appropriate Lottie frame, using audio analysis to align the frames with the phonemes at the correct time.

ps:this technique is currently complex to implement within FlutterFlow,, but we may consider it in the future.

some refrences: [basic-lip-sync](https://www.youtube.com/watch?v=JTz5slARQpA&pp=ygUMI2xpcHNpbmd2aXJh), [dynamic-lottie](https://www.youtube.com/watch?v=XX8jwNNV0U0), [lottie-frames](https://github.com/xvrh/lottie-flutter/issues/164)

</details>
<details>
  <summary>Ongoing conversation...</summary>
    
    Since the OpenAI API is stateless, you can maintain an ongoing conversation with saved history by creating an assistant in the OpenAI dashboard. Then, you can access it via the API endpoint.
    
    more about assistants [in this video](https://www.youtube.com/watch?v=LQ5xtsp7gYo)

</details>